"0","# 1. Data Preparation"
"0","# Select features and target variable"
"0","# Using Meta_score, No_of_Votes, Gross, Released_Year to predict Rating_Level"
"0","# IMDB_Rating is excluded as Rating_Level is directly derived from it."
"0","ml_data <- imdb %>%"
"0","  select(Meta_score, No_of_Votes, Gross, Released_Year, Rating_Level) %>%"
"0","  na.omit() # Remove rows with NA values for simplicity"
"0",""
"0","# Ensure Rating_Level is a factor"
"0","ml_data$Rating_Level <- as.factor(ml_data$Rating_Level)"
"0",""
"0","# Check if we have enough data after NA removal and for all factor levels"
"0","print(paste(""Number of rows in ml_data after na.omit:"", nrow(ml_data)))"
"1","[1] ""Number of rows in ml_data after na.omit: 842""
"
"0","print(""Table of Rating_Level in ml_data:"")"
"1","[1] ""Table of Rating_Level in ml_data:""
"
"0","print(table(ml_data$Rating_Level))"
"1","
Excellent      Good     Great 
        5       489       348 
"
"0","# Ensure there are at least two levels for Rating_Level and sufficient data"
"0","if (nrow(ml_data) < 50 || length(levels(ml_data$Rating_Level)) < 2) {"
"0","  print(""Not enough data or factor levels to proceed with model training."")"
"0","} else {"
"0","  # 2. Split data into training and testing sets"
"0","  set.seed(123) # for reproducibility"
"0","  trainIndex <- createDataPartition(ml_data$Rating_Level, p = .8, "
"0","                                    list = FALSE, "
"0","                                    times = 1)"
"0","  train_data <- ml_data[ trainIndex,]"
"0","  test_data  <- ml_data[-trainIndex,]"
"0","  "
"0","  print(paste(""Rows in training data:"", nrow(train_data)))"
"0","  print(paste(""Rows in test data:"", nrow(test_data)))"
"0","  print(""Distribution in training data:"")"
"0","  print(table(train_data$Rating_Level))"
"0","  print(""Distribution in test data:"")"
"0","  print(table(test_data$Rating_Level))"
"0",""
"0",""
"0","  # 3. Train the model using Random Forest"
"0","  # Define the training control"
"0","  train_control <- trainControl(method=""cv"", number=5) # 5-fold cross-validation"
"0",""
"0","  # Train the model"
"0","  # Note: Random Forest can take some time to train"
"0","  print(""Training Random Forest model..."")"
"0","  # Ensure all levels of Rating_Level are present in train_data"
"0","  if (length(levels(train_data$Rating_Level)) == length(levels(ml_data$Rating_Level))) {"
"0","      model_rf <- train(Rating_Level ~ ., "
"0","                        data=train_data, "
"0","                        method=""rf"", # rf for Random Forest"
"0","                        trControl=train_control,"
"0","                        # preProcess = c(""center"", ""scale""), # Optional: centering and scaling"
"0","                        tuneLength = 3) # Number of levels for each tuning parameter"
"0","      "
"0","      # Print model summary"
"0","      print(""Model Summary:"")"
"0","      print(model_rf)"
"0","      "
"0","      # 4. Make predictions on the test set"
"0","      predictions_rf <- predict(model_rf, test_data)"
"0","      "
"0","      # 5. Evaluate the model"
"0","      # Confusion Matrix"
"0","      print(""Confusion Matrix:"")"
"0","      # Ensure predictions_rf is a factor with the same levels as test_data$Rating_Level"
"0","      predictions_rf <- factor(predictions_rf, levels = levels(test_data$Rating_Level))"
"0","      "
"0","      cm <- confusionMatrix(predictions_rf, test_data$Rating_Level)"
"0","      print(cm)"
"0","      "
"0","      print(paste(""Overall Accuracy:"", cm$overall['Accuracy']))"
"0","      "
"0","      # Plot variable importance if the model supports it (Random Forest does)"
"0","      var_imp <- varImp(model_rf, scale = FALSE)"
"0","      print(""Variable Importance:"")"
"0","      print(var_imp)"
"0","      plot(var_imp, main=""Variable Importance for Predicting Rating Level"")"
"0",""
"0","  } else {"
"0","    print(""Skipping model training due to missing factor levels in training data after partitioning."")"
"0","    print(""Original levels:"")"
"0","    print(levels(ml_data$Rating_Level))"
"0","    print(""Train data levels:"")"
"0","    print(levels(train_data$Rating_Level))"
"0","  }"
"0","}"
"2","G1;H1;Errorh in createDataPartition(ml_data$Rating_Level, p = 0.8, list = FALSE,  : 
  could not find function ""createDataPartition""
Error during wrapup: not that many frames on the stack
Error: no more error handlers available (recursive errors?); invoking 'abort' restart
g"
